{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a319610b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import modules\n",
    "\n",
    "# Supress unnecessary warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import time, warnings\n",
    "import datetime as dt\n",
    "\n",
    "from IPython.display import display\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152a1a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "Read and understand the data\n",
    "\n",
    "xleads = pd.read_csv(r'C:\\Users\\indranil1\\Desktop\\Indranil-Personal\\Case Study\\Machine Learning\\Lead+Scoring+Case+Study\\Lead Scoring Assignment\\Leads.csv')\n",
    "\n",
    "# Look at the first few entries\n",
    "xleads.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9662b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the shape of the dataset\n",
    "\n",
    "xleads.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801fd445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the different columsn in the dataset\n",
    "\n",
    "xleads.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1b1d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "xleads.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4c2960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the summary of the dataset\n",
    "\n",
    "xleads.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bbc4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the info to see the types of the feature variables and the null values present\n",
    "\n",
    "xleads.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc409872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of missing values in each column\n",
    "\n",
    "xleads.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6055f9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all the columns in which greater than 3000 missing values are present\n",
    "\n",
    "for col in xleads.columns:\n",
    "    if xleads[col].isnull().sum() > 3000:\n",
    "        xleads.drop(col, 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735f3f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of null values again\n",
    "\n",
    "xleads.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798aef08",
   "metadata": {},
   "outputs": [],
   "source": [
    "xleads.drop(['City'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961bb60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same goes for the variable 'Country'\n",
    "\n",
    "xleads.drop(['Country'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca203bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now check the percentage of missing values in each column\n",
    "\n",
    "round(100*(xleads.isnull().sum()/len(xleads.index)), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3589c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of null values again\n",
    "\n",
    "xleads.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de63b40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the value counts of all the columns\n",
    "\n",
    "for column in xleads:\n",
    "    print(xleads[column].astype('category').value_counts())\n",
    "    print('___________________________________________________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efaa87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xleads['Lead Profile'].astype('category').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc4ea0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xleads['How did you hear about X Education'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19009be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xleads['Specialization'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cda3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "xleads.drop(['Lead Profile', 'How did you hear about X Education'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022cc3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "xleads.drop(['Do Not Call', 'Search', 'Magazine', 'Newspaper Article', 'X Education Forums', 'Newspaper', \n",
    "            'Digital Advertisement', 'Through Recommendations', 'Receive More Updates About Our Courses', \n",
    "            'Update me on Supply Chain Content', 'Get updates on DM Content', \n",
    "            'I agree to pay the amount through cheque'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee2eae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xleads['What matters most to you in choosing a course'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972a701f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the null value rows present in the variable 'What matters most to you in choosing a course'\n",
    "\n",
    "xleads.drop(['What matters most to you in choosing a course'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92164138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of null values again\n",
    "\n",
    "xleads.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d529d7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "xleads = xleads[~pd.isnull(xleads['What is your current occupation'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c2bc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of null values again\n",
    "\n",
    "xleads.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b75e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the null values rows in the column 'Lead Source'\n",
    "\n",
    "xleads = xleads[~pd.isnull(xleads['Lead Source'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617d14a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of null values again\n",
    "\n",
    "xleads.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da688228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the null values rows in the column 'Specialization'\n",
    "\n",
    "xleads = xleads[~pd.isnull(xleads['Specialization'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845da133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of null values again\n",
    "\n",
    "xleads.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a090e3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(xleads.index))\n",
    "print(len(xleads.index)/9240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b74593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the dataset again\n",
    "\n",
    "xleads.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f39645d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xleads.drop(['Prospect ID', 'Lead Number'], 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46440f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "xleads.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b68c77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare the data for modelling\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.pairplot(xleads,diag_kind='kde',hue='Converted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25b0b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xedu = xleads[['TotalVisits','Total Time Spent on Website','Page Views Per Visit','Converted']]\n",
    "sns.pairplot(xedu,diag_kind='kde',hue='Converted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f9ccb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "pt = PowerTransformer()\n",
    "transformedxedu = pd.DataFrame(pt.fit_transform(xedu))\n",
    "transformedxedu.columns = xedu.columns\n",
    "transformedxedu.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4d90c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(transformedxedu,diag_kind='kde',hue='Converted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d9d65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dummy variable creation\n",
    "\n",
    "#The next step is to deal with the categorical variables present in the dataset. So first take a look at which variables are actually categorical variables.\n",
    "\n",
    "# Check the columns which are of type 'object'\n",
    "\n",
    "temp = xleads.loc[:, xleads.dtypes == 'object']\n",
    "temp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed41830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy variables using the 'get_dummies' command\n",
    "dummy = pd.get_dummies(xleads[['Lead Origin', 'Lead Source', 'Do Not Email', 'Last Activity',\n",
    "                              'What is your current occupation','A free copy of Mastering The Interview', \n",
    "                              'Last Notable Activity']], drop_first=True)\n",
    "\n",
    "# Add the results to the master dataframe\n",
    "xleads = pd.concat([xleads, dummy], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014e0329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dummy variable separately for the variable 'Specialization' since it has the level 'Select' which is useless so we\n",
    "# drop that level by specifying it explicitly\n",
    "\n",
    "dummy_spl = pd.get_dummies(xleads['Specialization'], prefix = 'Specialization')\n",
    "dummy_spl = dummy_spl.drop(['Specialization_Select'], 1)\n",
    "xleads = pd.concat([xleads, dummy_spl], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bc5d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the variables for which the dummy variables have been created\n",
    "\n",
    "xleads = xleads.drop(['Lead Origin', 'Lead Source', 'Do Not Email', 'Last Activity',\n",
    "                   'Specialization', 'What is your current occupation',\n",
    "                   'A free copy of Mastering The Interview', 'Last Notable Activity'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae78c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the dataset again\n",
    "\n",
    "xleads.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8903b82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test-Train Split\n",
    "\n",
    "#The next step is to split the dataset into training an testing sets.\n",
    "\n",
    "# Import the required library\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Put all the feature variables in X\n",
    "\n",
    "X = xleads.drop(['Converted'], 1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9317a7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the target variable in y\n",
    "\n",
    "y = xleads['Converted']\n",
    "\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1e7e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into 70% train and 30% test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2909bfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling\n",
    "\n",
    "#Now there are a few numeric variables present in the dataset which have different scales. So let's go ahead and scale these variables.\n",
    "\n",
    "# Import MinMax scaler\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Scale the three numeric features present in the dataset\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train[['TotalVisits', 'Page Views Per Visit', 'Total Time Spent on Website']] = scaler.fit_transform(X_train[['TotalVisits', 'Page Views Per Visit', 'Total Time Spent on Website']])\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d32be2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking at the correlations\n",
    "\n",
    "#Let's now look at the correlations. Since the number of variables are pretty high, it's better that we look at the table instead of plotting a heatmap\n",
    "\n",
    "# Looking at the correlation table\n",
    "plt.figure(figsize = (25,15))\n",
    "sns.heatmap(xleads.corr())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97abe3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Building\n",
    "\n",
    "#Let's now move to model building. As you can see that there are a lot of variables present in the dataset which we cannot deal with. So the best way to approach this is to select a small set of features from this pool of variables using RFE.\n",
    "\n",
    "# Import 'LogisticRegression' and create a LogisticRegression object\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Import RFE and select 15 variables\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "rfe = RFE(logreg, 15)             # running RFE with 15 variables as output\n",
    "rfe = rfe.fit(X_train, y_train)\n",
    "\n",
    "# Let's take a look at which features have been selected by RFE\n",
    "\n",
    "list(zip(X_train.columns, rfe.support_, rfe.ranking_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542be90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put all the columns selected by RFE in the variable 'col'\n",
    "\n",
    "col = X_train.columns[rfe.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22755654",
   "metadata": {},
   "outputs": [],
   "source": [
    "Now you have all the variables selected by RFE and since we care about the statistics part, i.e. the p-values and the VIFs, let's use these variables to create a logistic regression model using statsmodels.\n",
    "\n",
    "# Select only the columns selected by RFE\n",
    "\n",
    "X_train = X_train[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c98454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statsmodels\n",
    "\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12a83ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a logistic Regression model on X_train after adding a constant and output the summary\n",
    "\n",
    "X_train_sm = sm.add_constant(X_train)\n",
    "logm2 = sm.GLM(y_train, X_train_sm, family = sm.families.Binomial())\n",
    "res = logm2.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b165c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import 'variance_inflation_factor'\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3c7675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a VIF dataframe for all the variables present\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train.columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e114392a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VIFs seem to be in a decent range except for three variables.\n",
    "\n",
    "#Let's first drop the variable Lead Source_Reference since it has a high p-value as well as a high VIF.\n",
    "\n",
    "X_train.drop('Lead Source_Reference', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355ca995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refit the model with the new set of features\n",
    "\n",
    "logm1 = sm.GLM(y_train,(sm.add_constant(X_train)), family = sm.families.Binomial())\n",
    "logm1.fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc7e219",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The variable Lead Profile_Dual Specialization Student also needs to be dropped.\n",
    "\n",
    "# Make a VIF dataframe for all the variables present\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train.columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ed1518",
   "metadata": {},
   "outputs": [],
   "source": [
    "The VIFs are now all less than 5. So let's drop the ones with the high p-values beginning with Last Notable Activity_Had a Phone Conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d95ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop('Last Notable Activity_Had a Phone Conversation', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8195d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refit the model with the new set of features\n",
    "\n",
    "logm1 = sm.GLM(y_train,(sm.add_constant(X_train)), family = sm.families.Binomial())\n",
    "logm1.fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f42d4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "Drop What is your current occupation_Housewife.\n",
    "\n",
    "X_train.drop('What is your current occupation_Housewife', axis = 1, inplace = True)\n",
    "\n",
    "# Refit the model with the new set of features\n",
    "\n",
    "logm1 = sm.GLM(y_train,(sm.add_constant(X_train)), family = sm.families.Binomial())\n",
    "logm1.fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eafe40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Drop What is your current occupation_Working Professional.\n",
    "\n",
    "X_train.drop('What is your current occupation_Working Professional', axis = 1, inplace = True)\n",
    "\n",
    "# Refit the model with the new set of features\n",
    "\n",
    "logm1 = sm.GLM(y_train,(sm.add_constant(X_train)), family = sm.families.Binomial())\n",
    "res = logm1.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b0beb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "All the p-values are now in the appropriate range. Let's also check the VIFs again in case we had missed something.\n",
    "\n",
    "# Make a VIF dataframe for all the variables present\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train.columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc7396a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model Evaluation\n",
    "\n",
    "Now, both the p-values and VIFs seem decent enough for all the variables. So let's go ahead and make predictions using this final set of features.\n",
    "\n",
    "# Use 'predict' to predict the probabilities on the train set\n",
    "\n",
    "y_train_pred = res.predict(sm.add_constant(X_train))\n",
    "y_train_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5a73ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping it into an array\n",
    "\n",
    "y_train_pred = y_train_pred.values.reshape(-1)\n",
    "y_train_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c70ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a dataframe with the actual conversion flag and the predicted probabilities\n",
    "\n",
    "# Create a new dataframe containing the actual conversion flag and the probabilities predicted by the model\n",
    "\n",
    "y_train_pred_final = pd.DataFrame({'Converted':y_train.values, 'Conversion_Prob':y_train_pred})\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20655209",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating new column 'Predicted' with 1 if Paid_Prob > 0.5 else 0\n",
    "\n",
    "y_train_pred_final['Predicted'] = y_train_pred_final.Conversion_Prob.map(lambda x: 1 if x > 0.5 else 0)\n",
    "\n",
    "# Let's see the head\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbb08e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now that you have the probabilities and have also made conversion predictions using them, it's time to evaluate the model.\n",
    "\n",
    "# Import metrics from sklearn for evaluation\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "# Create confusion matrix \n",
    "\n",
    "confusion = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.Predicted )\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95d327d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted     not_churn    churn\n",
    "# Actual\n",
    "# not_churn        2543      463\n",
    "# churn            692       1652  \n",
    "\n",
    "# Let's check the overall accuracy\n",
    "\n",
    "print(metrics.accuracy_score(y_train_pred_final.Converted, y_train_pred_final.Predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c03b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's evaluate the other metrics as well\n",
    "\n",
    "TP = confusion[1,1] # true positive \n",
    "TN = confusion[0,0] # true negatives\n",
    "FP = confusion[0,1] # false positives\n",
    "FN = confusion[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e5850b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the sensitivity\n",
    "\n",
    "TP/(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f88972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the specificity\n",
    "\n",
    "TN/(TN+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c0c32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Finding the Optimal Cutoff\n",
    "\n",
    "Now 0.5 was just arbitrary to loosely check the model performace. But in order to get good results, you need to optimise the threshold. So first let's plot an ROC curve to see what AUC we get.\n",
    "\n",
    "# ROC function\n",
    "\n",
    "def draw_roc( actual, probs ):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve( actual, probs,\n",
    "                                              drop_intermediate = False )\n",
    "    auc_score = metrics.roc_auc_score( actual, probs )\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.plot( fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score )\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    return None\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve( y_train_pred_final.Converted, y_train_pred_final.Conversion_Prob, drop_intermediate = False )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94489ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import matplotlib to plot the ROC curve\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Call the ROC function\n",
    "\n",
    "draw_roc(y_train_pred_final.Converted, y_train_pred_final.Conversion_Prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96919cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create columns with different probability cutoffs \n",
    "\n",
    "numbers = [float(x)/10 for x in range(10)]\n",
    "for i in numbers:\n",
    "    y_train_pred_final[i]= y_train_pred_final.Conversion_Prob.map(lambda x: 1 if x > i else 0)\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f73605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a dataframe to see the values of accuracy, sensitivity, and specificity at different values of probabiity cutoffs\n",
    "\n",
    "cutoff_df = pd.DataFrame( columns = ['prob','accuracy','sensi','speci'])\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# TP = confusion[1,1] # true positive \n",
    "# TN = confusion[0,0] # true negatives\n",
    "# FP = confusion[0,1] # false positives\n",
    "# FN = confusion[1,0] # false negatives\n",
    "\n",
    "num = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "for i in num:\n",
    "    cm1 = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final[i] )\n",
    "    total1=sum(sum(cm1))\n",
    "    accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
    "    \n",
    "    speci = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "    sensi = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "    cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\n",
    "print(cutoff_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb86fc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot it as well\n",
    "\n",
    "cutoff_df.plot.line(x='prob', y=['accuracy','sensi','speci'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32eeaa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final['final_predicted'] = y_train_pred_final.Conversion_Prob.map( lambda x: 1 if x > 0.42 else 0)\n",
    "\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eacc246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the accuracy now\n",
    "\n",
    "metrics.accuracy_score(y_train_pred_final.Converted, y_train_pred_final.final_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10642b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create the confusion matrix once again\n",
    "\n",
    "confusion2 = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.final_predicted )\n",
    "confusion2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a0e07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's evaluate the other metrics as well\n",
    "\n",
    "TP = confusion2[1,1] # true positive \n",
    "TN = confusion2[0,0] # true negatives\n",
    "FP = confusion2[0,1] # false positives\n",
    "FN = confusion2[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2382362b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Sensitivity\n",
    "\n",
    "TP/(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b786251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Specificity\n",
    "\n",
    "TN/(TN+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d824d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "Making Predictions on the Test Set\n",
    "\n",
    "Let's now make predicitons on the test set.\n",
    "\n",
    "# Scale the test set as well using just 'transform'\n",
    "\n",
    "X_test[['TotalVisits', 'Page Views Per Visit', 'Total Time Spent on Website']] = scaler.transform(X_test[['TotalVisits', 'Page Views Per Visit', 'Total Time Spent on Website']])\n",
    "\n",
    "# Select the columns in X_train for X_test as well\n",
    "\n",
    "X_test = X_test[col]\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28bad28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a constant to X_test\n",
    "\n",
    "X_test_sm = sm.add_constant(X_test[col])\n",
    "\n",
    "# Check X_test_sm\n",
    "\n",
    "X_test_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae62919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the required columns from X_test as well\n",
    "\n",
    "X_test.drop(['Lead Source_Reference', 'What is your current occupation_Housewife', \n",
    "             'What is your current occupation_Working Professional', 'Last Notable Activity_Had a Phone Conversation'], 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62e6183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set and store it in the variable 'y_test_pred'\n",
    "\n",
    "y_test_pred = res.predict(sm.add_constant(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f828d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3e19a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting y_pred to a dataframe\n",
    "\n",
    "y_pred_1 = pd.DataFrame(y_test_pred)\n",
    "\n",
    "# Let's see the head\n",
    "\n",
    "y_pred_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f3aede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting y_test to dataframe\n",
    "\n",
    "y_test_df = pd.DataFrame(y_test)\n",
    "\n",
    "# Remove index for both dataframes to append them side by side \n",
    "\n",
    "y_pred_1.reset_index(drop=True, inplace=True)\n",
    "y_test_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656555ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append y_test_df and y_pred_1\n",
    "\n",
    "y_pred_final = pd.concat([y_test_df, y_pred_1],axis=1)\n",
    "\n",
    "# Check 'y_pred_final'\n",
    "\n",
    "y_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17d56f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the column \n",
    "\n",
    "y_pred_final= y_pred_final.rename(columns = {0 : 'Conversion_Prob'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b2f9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the head of y_pred_final\n",
    "\n",
    "y_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee106312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set using 0.45 as the cutoff\n",
    "\n",
    "y_pred_final['final_predicted'] = y_pred_final.Conversion_Prob.map(lambda x: 1 if x > 0.42 else 0)\n",
    "\n",
    "# Check y_pred_final\n",
    "\n",
    "y_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71df781c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the overall accuracy\n",
    "\n",
    "metrics.accuracy_score(y_pred_final['Converted'], y_pred_final.final_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23892c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion2 = metrics.confusion_matrix(y_pred_final['Converted'], y_pred_final.final_predicted )\n",
    "confusion2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16de132c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = confusion2[1,1] # true positive \n",
    "TN = confusion2[0,0] # true negatives\n",
    "FP = confusion2[0,1] # false positives\n",
    "FN = confusion2[1,0] # false negatives\n",
    "\n",
    "# Calculate sensitivity\n",
    "TP / float(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac36ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate specificity\n",
    "TN / float(TN+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86aeae74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precision-Recall View\n",
    "\n",
    "#Let's now also build the training model using the precision-recall view\n",
    "\n",
    "#Looking at the confusion matrix again\n",
    "\n",
    "confusion = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.Predicted )\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6ac772",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precision\n",
    "\n",
    "#TP / TP + FP\n",
    "\n",
    "confusion[1,1]/(confusion[0,1]+confusion[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ad1da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recall\n",
    "\n",
    "#TP / TP + FN\n",
    "\n",
    "confusion[1,1]/(confusion[1,0]+confusion[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8902adcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precision and recall tradeoff\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "y_train_pred_final.Converted, y_train_pred_final.Predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb163175",
   "metadata": {},
   "outputs": [],
   "source": [
    "p, r, thresholds = precision_recall_curve(y_train_pred_final.Converted, y_train_pred_final.Conversion_Prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88357df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(thresholds, p[:-1], \"g-\")\n",
    "plt.plot(thresholds, r[:-1], \"r-\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a833b877",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final['final_predicted'] = y_train_pred_final.Conversion_Prob.map(lambda x: 1 if x > 0.44 else 0)\n",
    "\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bafc596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the accuracy now\n",
    "\n",
    "metrics.accuracy_score(y_train_pred_final.Converted, y_train_pred_final.final_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5867b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create the confusion matrix once again\n",
    "\n",
    "confusion2 = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.final_predicted )\n",
    "confusion2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c72a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's evaluate the other metrics as well\n",
    "\n",
    "TP = confusion2[1,1] # true positive \n",
    "TN = confusion2[0,0] # true negatives\n",
    "FP = confusion2[0,1] # false positives\n",
    "FN = confusion2[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40b18ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Precision\n",
    "\n",
    "TP/(TP+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ff0e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Recall\n",
    "\n",
    "TP/(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e12e854",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making Predictions on the Test Set\n",
    "\n",
    "#Let's now make predicitons on the test set.\n",
    "\n",
    "# Make predictions on the test set and store it in the variable 'y_test_pred'\n",
    "\n",
    "y_test_pred = res.predict(sm.add_constant(X_test))\n",
    "\n",
    "y_test_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8202522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting y_pred to a dataframe\n",
    "\n",
    "y_pred_1 = pd.DataFrame(y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9939b2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the head\n",
    "\n",
    "y_pred_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd4718e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting y_test to dataframe\n",
    "\n",
    "y_test_df = pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d88533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove index for both dataframes to append them side by side \n",
    "\n",
    "y_pred_1.reset_index(drop=True, inplace=True)\n",
    "y_test_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2197c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append y_test_df and y_pred_1\n",
    "\n",
    "y_pred_final = pd.concat([y_test_df, y_pred_1],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efab25f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check 'y_pred_final'\n",
    "\n",
    "y_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99f20a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the column \n",
    "\n",
    "y_pred_final= y_pred_final.rename(columns = {0 : 'Conversion_Prob'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a3d254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the head of y_pred_final\n",
    "\n",
    "y_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3c1777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set using 0.44 as the cutoff\n",
    "\n",
    "y_pred_final['final_predicted'] = y_pred_final.Conversion_Prob.map(lambda x: 1 if x > 0.44 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7e1a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check y_pred_final\n",
    "\n",
    "y_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909b8f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the overall accuracy\n",
    "\n",
    "metrics.accuracy_score(y_pred_final['Converted'], y_pred_final.final_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfabfdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion2 = metrics.confusion_matrix(y_pred_final['Converted'], y_pred_final.final_predicted )\n",
    "confusion2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f1b003",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = confusion2[1,1] # true positive \n",
    "TN = confusion2[0,0] # true negatives\n",
    "FP = confusion2[0,1] # false positives\n",
    "FN = confusion2[1,0] # false negatives\n",
    "\n",
    "# Calculate Precision\n",
    "\n",
    "TP/(TP+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77902909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Recall\n",
    "\n",
    "TP/(TP+FN)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
